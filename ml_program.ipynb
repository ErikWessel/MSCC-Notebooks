{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "import yaml\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision.models import (EfficientNet_V2_S_Weights, Swin_V2_S_Weights,\n",
    "                                efficientnet_v2_s, swin_v2_s)\n",
    "\n",
    "from ml_commons import *\n",
    "\n",
    "cudnn.benchmark = True\n",
    "sns.set_theme()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load configuration file that specifies training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open('ml_config.yml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix_dir = config['paths']['prefix_dir']\n",
    "dataset_dir = os.path.join(prefix_dir, config['paths']['dataset_dir'])\n",
    "output_dir = os.path.join(config['paths']['machine_learning_dir'], 'output')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Release memory to ensure enough capacity on the selected device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model using transfer learning from either EfficientNetV2 or SwinTransformerV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(model:nn.Module, name:str):\n",
    "    spacing = '  '\n",
    "    model_str = spacing + f'\\n{spacing}'.join(str(model).splitlines())\n",
    "    print(f'--- {name} ---\\n{model_str}\\n{\"-\" * (8 + len(name))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: EfficientNet\n",
      "--- Initial Model Head ---\n",
      "  Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=True)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      "--------------------------\n",
      "Classification layer has 1280 input features\n",
      "--- Modified Model Head ---\n",
      "  Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=5, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f'Using model: ' + config['model']['name'])\n",
    "model_name = str(config['model']['name']).lower()\n",
    "use_transfer_learning = config['model']['use_transfer_learning']\n",
    "if model_name == 'swintransformer':\n",
    "    model = swin_v2_s(weights = Swin_V2_S_Weights.DEFAULT if use_transfer_learning else None)\n",
    "elif model_name == 'efficientnet':\n",
    "    model = efficientnet_v2_s(weights = EfficientNet_V2_S_Weights.DEFAULT if use_transfer_learning else None)\n",
    "else:\n",
    "    raise RuntimeError(f'Model \"' + config['model']['name'] + '\" is unknown')\n",
    "\n",
    "if config['model']['freeze_parameters']:\n",
    "    for param in model.parameters(): #freeze model\n",
    "        param.requires_grad = False\n",
    "\n",
    "print_model(get_model_head(model), 'Initial Model Head')\n",
    "num_features = get_num_features(model)\n",
    "print(f'Classification layer has {num_features} input features')\n",
    "new_model_head = nn.Sequential()\n",
    "# Before linear layer\n",
    "if config['processing']['use_dropout']:\n",
    "    new_model_head.append(nn.Dropout(p=config['processing']['dropout_p'], inplace=True))\n",
    "# Linear layer\n",
    "linear_layer = nn.Linear(num_features, 1 if config['processing']['use_one_neuron_regression'] else len(classes))\n",
    "new_model_head.append(linear_layer)\n",
    "# After linear layer\n",
    "if (config['processing']['use_ordinal_regression'] or config['processing']['use_one_neuron_regression']) \\\n",
    "        and config['processing']['activation_function'] != False:\n",
    "    activation_function = str(config['processing']['activation_function']).lower()\n",
    "    if activation_function == 'sigmoid':\n",
    "        activation_function = nn.Sigmoid()\n",
    "    elif activation_function == 'relu':\n",
    "        activation_function = nn.ReLU()\n",
    "    elif activation_function == 'tanh':\n",
    "        activation_function = nn.Tanh()\n",
    "    else:\n",
    "        raise RuntimeError(f'Unkown activation function: {activation_function}')\n",
    "    new_model_head = new_model_head.append(activation_function)\n",
    "\n",
    "set_model_head(model, new_model_head)\n",
    "print_model(get_model_head(model), 'Modified Model Head')\n",
    "# model = nn.DataParallel(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weights and define prerequisite functions for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>CLR</th>\n",
       "      <th>FEW</th>\n",
       "      <th>SCT</th>\n",
       "      <th>BKN</th>\n",
       "      <th>OVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>2.505284</td>\n",
       "      <td>13.22179</td>\n",
       "      <td>9.509328</td>\n",
       "      <td>6.538807</td>\n",
       "      <td>3.743665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label        CLR       FEW       SCT       BKN       OVC\n",
       "weight  2.505284  13.22179  9.509328  6.538807  3.743665"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_weights = pd.read_csv(os.path.join(dataset_dir, 'training_weights.csv'), index_col='label')\n",
    "training_weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_label_ordinal_regression(pred: torch.Tensor) -> torch.Tensor:\n",
    "    return (pred > 0.5).cumprod(axis=1).sum(axis=1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalRegression:\n",
    "    def __init__(self, weights:Optional[torch.Tensor]) -> None:\n",
    "        if weights is None:\n",
    "            self.weights = torch.Tensor([1] * len(classes)).to(device)\n",
    "        else:\n",
    "            self.weights = weights\n",
    "    def __call__(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        modified_targets = torch.zeros_like(predictions)\n",
    "        for i, target in enumerate(targets):\n",
    "            modified_targets[i, 0 : target + 1] = 1\n",
    "        loss_function_name = str(config['processing']['ordinal_regression_loss']).lower()\n",
    "        if loss_function_name == 'mse':\n",
    "            loss = torch.mean((nn.MSELoss(reduction='none')(predictions, modified_targets) * self.weights).sum(axis=1))\n",
    "        elif loss_function_name == 'l1':\n",
    "            loss = torch.mean((nn.L1Loss(reduction='none')(predictions, modified_targets) * self.weights).sum(axis=1))\n",
    "        else:\n",
    "            raise RuntimeError(f'Unknown loss function: {loss_function_name}')\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_label_one_neuron_regression(pred: torch.Tensor) -> torch.Tensor:\n",
    "    return ((pred * max(classes)).round()).int().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneNeuronRegression:\n",
    "    def __call__(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        modified_predictions = predictions.flatten()\n",
    "        classes_max = max(classes)\n",
    "        loss_function_name = str(config['processing']['ordinal_regression_loss']).lower()\n",
    "        if loss_function_name == 'mse':\n",
    "            loss = torch.mean(nn.MSELoss(reduction='none')(modified_predictions * classes_max, targets.float()))\n",
    "        elif loss_function_name == 'l1':\n",
    "            loss = torch.mean(nn.L1Loss(reduction='none')(modified_predictions * classes_max, targets.float()))\n",
    "        else:\n",
    "            raise RuntimeError(f'Unknown loss function: {loss_function_name}')\n",
    "        return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets and apply techniques like data augmentation or use a weighted sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_transforms = [\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "]\n",
    "composed_transforms = transforms.Compose(dataset_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_manual_labels = config['processing']['use_manual_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset       = AimlsseImageDataset(DatasetType.TRAINING,     dataset_dir, transfrom=composed_transforms, use_manual_labels=use_manual_labels)\n",
    "validation_dataset  = AimlsseImageDataset(DatasetType.VALIDATION,   dataset_dir, transfrom=None, use_manual_labels=use_manual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std(loader:DataLoader):\n",
    "  sum, squared_sum, num_batches = 0,0,0\n",
    "  for data, _, _ in loader:\n",
    "    sum += torch.mean(data,dim=[0,1,2])\n",
    "    squared_sum += torch.mean(data**2,dim=[0,1,2])\n",
    "    num_batches += 1\n",
    "  mean = sum/num_batches\n",
    "  std = (squared_sum/num_batches - mean**2)**0.5\n",
    "  return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalization(dataset:AimlsseImageDataset, dataset_type:DatasetType, dataset_transforms):\n",
    "    mean, std = mean_std(dataset)\n",
    "    print(f'{dataset_type.name} - mean {mean:.3f}, std {std:.3f}')\n",
    "    if dataset_transforms is None:\n",
    "        dataset_transforms = []\n",
    "    return AimlsseImageDataset(dataset_type, dataset_dir,\n",
    "                               transfrom = transforms.Compose(dataset_transforms + [transforms.Normalize(mean, std)]),\n",
    "                               use_manual_labels=use_manual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['processing']['batch_normalization']:\n",
    "    train_dataset       = batch_normalization(train_dataset, DatasetType.TRAINING, dataset_transforms)\n",
    "    validation_dataset  = batch_normalization(validation_dataset, DatasetType.VALIDATION, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['processing']['use_weighted_sampler']:\n",
    "    num_samples = len(train_dataset)\n",
    "    weights = [0] * num_samples\n",
    "    for i in range(num_samples):\n",
    "        label = train_dataset.get_label(i)\n",
    "        weights[i] = training_weights.loc[class_names]['weight'].iloc[label]\n",
    "    training_sampler = WeightedRandomSampler(weights, num_samples)\n",
    "    train_dataloader =  DataLoader(train_dataset,       batch_size=config['processing']['batch_size'], sampler=training_sampler)\n",
    "else:\n",
    "    train_dataloader =  DataLoader(train_dataset,       batch_size=config['processing']['batch_size'], shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset,  batch_size=config['processing']['batch_size'], shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If enabled in the config file, show example images of the dataset with corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config['output']['show_samples']:\n",
    "    plot_samples(train_dataset, config['processing']['batch_size'], sample_batch_index)\n",
    "    sample_batch_index += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all prerequisites that are necessary for model training, depending on the settings in the configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss weights: None\n"
     ]
    }
   ],
   "source": [
    "if config['processing']['use_weighted_loss_function']:\n",
    "    loss_function_weights = torch.tensor(training_weights['weight'].to_list())\n",
    "    loss_function_weights = loss_function_weights.to(device)\n",
    "else:\n",
    "    loss_function_weights = None\n",
    "print(f'Loss weights: {loss_function_weights}')\n",
    "\n",
    "if config['processing']['use_ordinal_regression']:\n",
    "    criterion = OrdinalRegression(loss_function_weights)\n",
    "    outputs_to_predictions = prediction_to_label_ordinal_regression\n",
    "elif config['processing']['use_one_neuron_regression']:\n",
    "    criterion = OneNeuronRegression()\n",
    "    if loss_function_weights is not None:\n",
    "        raise Warning('Unable to use one neuron regression with loss function weights')\n",
    "    outputs_to_predictions = prediction_to_label_one_neuron_regression\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss(loss_function_weights)\n",
    "    outputs_to_predictions = lambda outputs: torch.max(outputs, 1)[1]\n",
    "\n",
    "learning_rate = math.pow(10, -config['processing']['learning_rate_exp'])\n",
    "weight_decay = math.pow(10, -config['processing']['weight_decay_exp']) if config['processing']['use_weight_decay'] else 0.0\n",
    "optimizer_name = str(config['processing']['optimizer']).lower()\n",
    "if optimizer_name == 'adam':\n",
    "    optimizer = optim.Adam(get_model_head(model).parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "elif optimizer_name == 'sgd':\n",
    "    optimizer = optim.SGD(get_model_head(model).parameters(), lr=learning_rate, momentum=config['processing']['momentum'])\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Checkpoints will be stored in: ML\\checkpoints\\chk.pt\n",
      "The results will be stored in: ML\\output\\efficientnet_v2_s_preset_3_16km_300_weighted_sampler_ord_regr_batchacc_all.pt\n",
      "Epoch 0/31\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604a3761aaeb472b904e1841866561d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 319.3 [s]\n",
      "\tLoss: 0.0020 Acc: 0.0753\n",
      "\tCLR - Precision: 0.181 Recall: 0.246 F1-Score: 0.208\n",
      "\tFEW - Precision: 0.218 Recall: 0.072 F1-Score: 0.109\n",
      "\tSCT - Precision: 0.234 Recall: 0.019 F1-Score: 0.035\n",
      "\tBKN - Precision: 0.217 Recall: 0.027 F1-Score: 0.048\n",
      "\tOVC - Precision: 0.177 Recall: 0.018 F1-Score: 0.032\n",
      "Total -> Precision: 0.205 Recall: 0.075 F1-Score: 0.086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f932862d0d60441aaeeb93c3a7f955d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation took 8.1 [s]\n",
      "\tLoss: 0.0019 Acc: 0.1292\n",
      "\tCLR - Precision: 0.323 Recall: 0.163 F1-Score: 0.217\n",
      "\tFEW - Precision: 0.037 Recall: 0.093 F1-Score: 0.053\n",
      "\tSCT - Precision: 0.060 Recall: 0.151 F1-Score: 0.086\n",
      "\tBKN - Precision: 0.123 Recall: 0.108 F1-Score: 0.115\n",
      "\tOVC - Precision: 0.367 Recall: 0.072 F1-Score: 0.121\n",
      "Total -> Precision: 0.272 Recall: 0.129 F1-Score: 0.162\n",
      "Epoch 1/31\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144b59d91da04c67b7fa9a10ef67eea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 235.1 [s]\n",
      "\tLoss: 0.0018 Acc: 0.1545\n",
      "\tCLR - Precision: 0.165 Recall: 0.159 F1-Score: 0.162\n",
      "\tFEW - Precision: 0.224 Recall: 0.151 F1-Score: 0.180\n",
      "\tSCT - Precision: 0.196 Recall: 0.289 F1-Score: 0.233\n",
      "\tBKN - Precision: 0.202 Recall: 0.145 F1-Score: 0.169\n",
      "\tOVC - Precision: 0.280 Recall: 0.029 F1-Score: 0.053\n",
      "Total -> Precision: 0.213 Recall: 0.155 F1-Score: 0.160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86bb1e8d15d49d5bac77e90ebef6331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation took 8.1 [s]\n",
      "\tLoss: 0.0018 Acc: 0.1174\n",
      "\tCLR - Precision: 0.361 Recall: 0.088 F1-Score: 0.141\n",
      "\tFEW - Precision: 0.031 Recall: 0.107 F1-Score: 0.048\n",
      "\tSCT - Precision: 0.081 Recall: 0.462 F1-Score: 0.137\n",
      "\tBKN - Precision: 0.179 Recall: 0.165 F1-Score: 0.172\n",
      "\tOVC - Precision: 0.500 Recall: 0.052 F1-Score: 0.095\n",
      "Total -> Precision: 0.332 Recall: 0.117 F1-Score: 0.128\n",
      "Epoch 2/31\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d2de38796e45f78353ef718b0896eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m output_filepath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(config[\u001b[39m'\u001b[39m\u001b[39mpaths\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmachine_learning_dir\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m, config[\u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39moutput_name\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe results will be stored in: \u001b[39m\u001b[39m{\u001b[39;00moutput_filepath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m model_trained \u001b[39m=\u001b[39m train_model(model, device, model_data, criterion, outputs_to_predictions, optimizer, scheduler,\n\u001b[0;32m      7\u001b[0m                             checkpoint_filepath, num_epochs\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mprocessing\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mnum_epochs\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      8\u001b[0m                             batch_accumulation\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mprocessing\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mbatch_accumulation\u001b[39;49m\u001b[39m'\u001b[39;49m], config\u001b[39m=\u001b[39;49mconfig)\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCopying data from checkpoint to results..\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m state \u001b[39m=\u001b[39m load_state(checkpoint_filepath)\n",
      "File \u001b[1;32mc:\\Users\\erikw\\Documents\\Uni\\Master\\Semester 5\\Master Thesis\\python\\aimlsse\\notebooks\\ml_commons.py:280\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, device, data, criterion, outputs_to_predictions, optimizer, scheduler, checkpoint_filepath, num_epochs, batch_accumulation, load_checkpoint, config)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mif\u001b[39;00m batch_accumulation \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mall\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    279\u001b[0m     batch_accumulation \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataloader)\n\u001b[1;32m--> 280\u001b[0m \u001b[39mfor\u001b[39;00m batch_index, (inputs, labels, indices) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(dataloader)):\n\u001b[0;32m    281\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    282\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\lib\\site-packages\\tqdm\\notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[1;32m--> 254\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[0;32m    255\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    256\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m    257\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\erikw\\Documents\\Uni\\Master\\Semester 5\\Master Thesis\\python\\aimlsse\\notebooks\\ml_commons.py:67\u001b[0m, in \u001b[0;36mAimlsseImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, \u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]:\n\u001b[1;32m---> 67\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_image(index)\n\u001b[0;32m     68\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_label(index)\n\u001b[0;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m image, label, index\n",
      "File \u001b[1;32mc:\\Users\\erikw\\Documents\\Uni\\Master\\Semester 5\\Master Thesis\\python\\aimlsse\\notebooks\\ml_commons.py:78\u001b[0m, in \u001b[0;36mAimlsseImageDataset.get_image\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39m# Select label and perform transformations\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[1;32m---> 78\u001b[0m     image_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(image_tensor)\n\u001b[0;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m image_tensor\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:705\u001b[0m, in \u001b[0;36mRandomHorizontalFlip.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    699\u001b[0m \u001b[39m    img (PIL Image or Tensor): Image to be flipped.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m    PIL Image or Tensor: Randomly flipped image.\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp:\n\u001b[1;32m--> 705\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mhflip(img)\n\u001b[0;32m    706\u001b[0m \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:654\u001b[0m, in \u001b[0;36mhflip\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m    652\u001b[0m     \u001b[39mreturn\u001b[39;00m F_pil\u001b[39m.\u001b[39mhflip(img)\n\u001b[1;32m--> 654\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39;49mhflip(img)\n",
      "File \u001b[1;32mc:\\Users\\erikw\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:129\u001b[0m, in \u001b[0;36mhflip\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhflip\u001b[39m(img: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    127\u001b[0m     _assert_image_tensor(img)\n\u001b[1;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mflip(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_data = ModelData(train_dataset, validation_dataset, train_dataloader, validation_dataloader)\n",
    "checkpoint_filepath = os.path.join(config['paths']['machine_learning_dir'], 'checkpoints', 'chk.pt')\n",
    "print(f'Model Checkpoints will be stored in: {checkpoint_filepath}')\n",
    "output_filepath = os.path.join(config['paths']['machine_learning_dir'], 'output', config['output']['output_name'])\n",
    "print(f'The results will be stored in: {output_filepath}')\n",
    "model_trained = train_model(model, device, model_data, criterion, outputs_to_predictions, optimizer, scheduler,\n",
    "                            checkpoint_filepath, num_epochs=config['processing']['num_epochs'],\n",
    "                            batch_accumulation=config['processing']['batch_accumulation'], config=config)\n",
    "print('Copying data from checkpoint to results..')\n",
    "state = load_state(checkpoint_filepath)\n",
    "save_state(output_filepath, state)\n",
    "print(f'Results stored in: {output_filepath}')\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d581a96df5f4d85c539a287c4f6ef29fb4dda2cc3374c000ae58cf3e6d0b188e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
